import tweepy
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
import schedule
import time
import os
from dotenv import load_dotenv
import re
import random
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Twitter API credentials
CONSUMER_KEY = os.getenv("CONSUMER_KEY")
CONSUMER_SECRET = os.getenv("CONSUMER_SECRET")
ACCESS_TOKEN = os.getenv("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = os.getenv("ACCESS_TOKEN_SECRET")

# Authentication for Twitter API
auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)

# Load a fine-tuned model for more thematic text generation
model_name = "grok/xAI-waluigi"  # Hypothetical model fine-tuned for Waluigi-like speech
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)
generator = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=100)

def generate_waluigi_response(prompt):
    """
    Generate a response in the style of Waluigi.
    :param prompt: The initial prompt for text generation.
    :return: A string response.
    """
    try:
        response = generator(prompt, temperature=0.7, num_return_sequences=1)
        return response[0]['generated_text'].split(prompt)[1].strip()
    except Exception as e:
        logger.error(f"Error generating response: {e}")
        return "Wah! I'm stuck! Try again later!"

def is_offensive(text):
    """
    Check if the text contains potentially offensive content.
    :param text: The text to check.
    :return: Boolean indicating if the text is offensive.
    """
    offensive_patterns = [
        r"\b(hate|mock|harass|insult|stupid|dumb|idiot)\b",
        r"you're?\s+(ugly|bad|worthless|useless)"
    ]
    return any(re.search(pattern, text.lower()) for pattern in offensive_patterns)

def safe_generate_waluigi_response(prompt):
    """
    Generate a safe, non-offensive response.
    :param prompt: The prompt for generating text.
    :return: A string response or a fallback message.
    """
    response = generate_waluigi_response(prompt)
    if is_offensive(response):
        return "Wah! I'm being nice today!"
    return response

# More varied prompts for generating content
prompts = [
    "Waluigi thinks about",
    "Waluigi says to his friends",
    "Waluigi muses on the philosophy of",
    "Waluigi wonders why",
    "Waluigi's response to",
    "Waluigi's take on"
]

# Additional content for tweets
hashtags = ["#WaluigiWisdom", "#WaluigiWonders", "#WaluigiSays"]
emojis = ["ðŸ¤”", "ðŸ˜", "ðŸ™„", "ðŸ’¡", "ðŸ†"]

def post_tweet():
    """
    Post a tweet with generated content from Waluigi, including hashtags and an emoji.
    """
    prompt = random.choice(prompts)
    subject = random.choice(["games", "life", "Mario", "adventures", "friendship", "evil"])
    full_prompt = f"{prompt} {subject}?"
    content = safe_generate_waluigi_response(full_prompt)
    
    # Clean up the tweet content to ensure it fits within Twitter's character limit
    content = re.sub(r'\s+', ' ', content).strip()[:250]  # Leave space for hashtags and emoji
    hashtag = random.choice(hashtags)
    emoji = random.choice(emojis)
    tweet_content = f"{content} {hashtag} {emoji}"
    
    try:
        api.update_status(tweet_content)
        logger.info(f"Tweet posted: {tweet_content}")
    except tweepy.TweepError as e:
        logger.error(f"Error posting tweet: {e}")
        # Log the full content for debugging if needed
        logger.debug(f"Full tweet content: {tweet_content}")

def monitor_replies():
    """
    Monitor mentions and reply in Waluigi's style.
    """
    for mention in api.mentions_timeline(since_id=last_mention_id):
        if mention.id > last_mention_id:
            last_mention_id = mention.id  # Update the last seen mention ID
            prompt = f"Waluigi replies to: {mention.text}"
            reply = safe_generate_waluigi_response(prompt)
            try:
                api.update_status(f"@{mention.user.screen_name} {reply}", mention.id)
                logger.info(f"Replied to mention: {reply}")
            except tweepy.TweepError as e:
                logger.error(f"Error replying to tweet: {e}")

# Global variable for tracking the last mention ID (you would initialize this from a file or db)
last_mention_id = 0

def main():
    """
    Main function to run the bot with scheduled tweet posting and mention monitoring.
    """
    logger.info("Starting Waluigi Twitter Bot...")
    
    # Schedule the bot to tweet every hour and check mentions every 15 minutes
    schedule.every().hour.at(":00").do(post_tweet)
    schedule.every(15).minutes.do(monitor_replies)
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("Stopping Waluigi Twitter Bot...")

if __name__ == "__main__":
    main()
